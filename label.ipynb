{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18182c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d14af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the folder containing your dataset\n",
    "# Adjust this path to where you saved the images\n",
    "dataset_folder = 'DS203-2025-S1-E7-project-images/images/'\n",
    "\n",
    "# We will store the loaded images in a list\n",
    "loaded_images = []\n",
    "# It's also useful to store their filenames\n",
    "image_filenames = []\n",
    "\n",
    "print(f\"Starting to load images from: {dataset_folder}\")\n",
    "\n",
    "# Loop through every file in the folder\n",
    "for filename in os.listdir(dataset_folder):\n",
    "    \n",
    "    # Check if the file is an image (e.g., .jpg, .png)\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "        \n",
    "        # Create the full path to the image\n",
    "        image_path = os.path.join(dataset_folder, filename)\n",
    "        \n",
    "        # Load the image using OpenCV\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is not None:\n",
    "            # If loading was successful, add it to our list\n",
    "            loaded_images.append(image)\n",
    "            image_filenames.append(filename)\n",
    "        else:\n",
    "            print(f\"Warning: Could not load {filename}\")\n",
    "\n",
    "print(f\"---\")\n",
    "print(f\"Success! Loaded {len(loaded_images)} images.\")\n",
    "print(f\"Example: The first image '{image_filenames[0]}' has dimensions: {loaded_images[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9872a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \"\"\"\n",
    "    Combines all preprocessing and splitting into one function.\n",
    "    \n",
    "    1. Applies all project rules (crop, no-upscale, downscale).\n",
    "    2. If valid, splits the 800x600 image into an 8x8 grid.\n",
    "    \n",
    "    Returns: \n",
    "        - A list of 64 (100x75) image cells if successful.\n",
    "        - None if the image is discarded.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Part 1: Processing (Same as before) ---\n",
    "    TARGET_WIDTH = 800\n",
    "    TARGET_HEIGHT = 600\n",
    "    TARGET_ASPECT = TARGET_WIDTH / TARGET_HEIGHT\n",
    "    \n",
    "    h, w = image.shape[:2]\n",
    "    original_aspect = w / h\n",
    "    \n",
    "    processed_image = image\n",
    "    \n",
    "    if abs(original_aspect - TARGET_ASPECT) > 0.01:\n",
    "        if original_aspect > TARGET_ASPECT:\n",
    "            new_width = int(h * TARGET_ASPECT)\n",
    "            left = (w - new_width) // 2\n",
    "            right = left + new_width\n",
    "            processed_image = image[:, left:right]\n",
    "        else:\n",
    "            new_height = int(w / TARGET_ASPECT)\n",
    "            top = (h - new_height) // 2\n",
    "            bottom = top + new_height\n",
    "            processed_image = image[top:bottom, :]\n",
    "            \n",
    "    h, w = processed_image.shape[:2]\n",
    "    \n",
    "    if w < TARGET_WIDTH or h < TARGET_HEIGHT:\n",
    "        return None  # Discard\n",
    "        \n",
    "    if w > TARGET_WIDTH or h > TARGET_HEIGHT:\n",
    "        processed_image = cv2.resize(processed_image, \n",
    "                                     (TARGET_WIDTH, TARGET_HEIGHT), \n",
    "                                     interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # At this point, 'processed_image' is a valid 800x600 image.\n",
    "\n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a16e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loaded {len(loaded_images)} images. Now processing and filtering...\")\n",
    "final_images = []\n",
    "final_filenames = []\n",
    "\n",
    "# Use zip() to loop over both lists at the same time\n",
    "for (image, filename) in zip(loaded_images, image_filenames):\n",
    "    \n",
    "    # Process the imag\n",
    "# Now, 'final_grids[i]' is the list of 64 cells\n",
    "# that belongs to 'final_filenames[i]'e using your combined function\n",
    "    final_image = process_image(image)\n",
    "    \n",
    "    # --- This is the critical check ---\n",
    "    # Only keep the grid AND its filename if processing was successful\n",
    "    if final_image is not None:\n",
    "        final_images.append(final_image)\n",
    "        final_filenames.append(filename)\n",
    "\n",
    "print(\"---\")\n",
    "print(\"Processing complete.\")\n",
    "print(f\"Kept {len(final_filenames)} valid images for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e464c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = YOLO('yolov8n.pt') \n",
    "MODEL_TYPE = \"vit_b\"  # or \"vit_b\"\n",
    "CHECKPOINT_PATH = \"sam_vit_b_01ec64.pth\" # Your downloaded model path\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH)\n",
    "sam.to(device=DEVICE)\n",
    "predictor = SamPredictor(sam)\n",
    "OUTPUT_FOLDER = 'Yolo_SAM'\n",
    "out_dir = os.path.join(OUTPUT_FOLDER)\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db93eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_box(image_bgr, conf_thresh=0.3):\n",
    "    results = detector(image_bgr, verbose=False)\n",
    "    input_boxes = []\n",
    "    if results and results[0].boxes:  # Check if any boxes were detected\n",
    "        boxes = results[0].boxes\n",
    "        coords = boxes.xyxy.cpu().numpy()    # shape (N,4)\n",
    "        confs = boxes.conf.cpu().numpy()     # shape (N,)\n",
    "        cls_ids = boxes.cls.cpu().numpy().astype(int)  # shape (N,)\n",
    "\n",
    "        for i in range(len(confs)):\n",
    "            input_box = coords[i]\n",
    "            class_id = int(cls_ids[i])\n",
    "            confidence = float(confs[i])\n",
    "            class_name = detector.names.get(class_id, str(class_id))\n",
    "            if confidence >= conf_thresh:\n",
    "                input_boxes.append(input_box)\n",
    "        if input_boxes :\n",
    "            return input_boxes\n",
    "        else:\n",
    "            print(len(results[0].boxes))\n",
    "            print(\"No Boxes found with thres > 0.35\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"âŒ No objects detected by YOLOv8.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988722d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_image(image_bgr, image_path):\n",
    "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "    # Set the image for the predictor\n",
    "    predictor.set_image(image_rgb)\n",
    "    input_boxes = detect_box(image_bgr)\n",
    "    if not input_boxes:\n",
    "        print(\"No boxes to mask.\")\n",
    "        return None\n",
    "\n",
    "    combined_mask = None\n",
    "    for box in input_boxes:\n",
    "        masks, scores, logits = predictor.predict(\n",
    "            box=box,                # provide a single box (shape (4,))\n",
    "            multimask_output=False\n",
    "        )\n",
    "        mask = masks[0]  # boolean mask for this box\n",
    "        if combined_mask is None:\n",
    "            combined_mask = mask.copy()\n",
    "        else:\n",
    "            combined_mask |= mask     # union of masks\n",
    "\n",
    "    mask_uint8 = combined_mask.astype(np.uint8) * 255\n",
    "    mask_color = cv2.cvtColor(mask_uint8, cv2.COLOR_GRAY2BGR)\n",
    "    mask_bool = combined_mask.astype(bool)\n",
    "\n",
    "    # Option A: Color tint overlay (BGR color, here red)\n",
    "    color = np.array([0, 0, 255], dtype=np.uint8)  # BGR\n",
    "    alpha = 0.6  # overlay strength on animal region (0..1)\n",
    "\n",
    "    colored = np.zeros_like(image_bgr, dtype=np.uint8)\n",
    "    colored[:] = color\n",
    "\n",
    "    # Blend only where mask is True\n",
    "    blended = image_bgr.copy()\n",
    "    blended[mask_bool] = (image_bgr[mask_bool].astype(np.float32) * (1 - alpha) +\n",
    "                          color.astype(np.float32) * alpha).astype(np.uint8)\n",
    "\n",
    "    # Save visuals for inspection\n",
    "    out_name= f\"{image_path}_mask\"\n",
    "    out_path = os.path.join(out_dir, out_name)\n",
    "    cv2.imwrite(out_path, blended)\n",
    "    return combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17f20fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = {}\n",
    "count = 0\n",
    "for image, filepath in zip(final_images, final_filenames):\n",
    "    count += 1\n",
    "    print(f\"processing image {count}: {filepath}\")\n",
    "    masks[filepath] = mask_image(image, filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_label_in_cell(mask):\n",
    "    \"\"\"\n",
    "    Returns 1 if >=80% of pixels in `mask` are True/foreground, else 0.\n",
    "    Accepts boolean mask or 0/1 uint8 array of any shape.\n",
    "    \"\"\"\n",
    "    mask_bool = np.asarray(mask).astype(bool)\n",
    "    total_pixels = mask_bool.size\n",
    "    total_wildlife_pixels = int(mask_bool.sum())\n",
    "    return 1 if (total_wildlife_pixels / total_pixels) >= 0.2 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "final_df = pd.DataFrame(columns=[\"cell_Image_path\", \"Image_path\",\"label\"])\n",
    "final_grid = []\n",
    "final_label = []\n",
    "CELL_OUTPUT_FOLDER = 'Cell_Images'\n",
    "cells_dir = os.path.join(CELL_OUTPUT_FOLDER)\n",
    "os.makedirs(cells_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545077e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TARGET_WIDTH = 800\n",
    "TARGET_HEIGHT = 600\n",
    "def make_grid(image,image_mask,path):\n",
    "    GRID_ROWS = 8\n",
    "    GRID_COLS = 8\n",
    "    # Calculate the size of each cell\n",
    "    # 800 / 8 = 100 pixels wide\n",
    "    # 600 / 8 = 75 pixels high\n",
    "    cell_height = TARGET_HEIGHT // GRID_ROWS  # 75\n",
    "    cell_width = TARGET_WIDTH // GRID_COLS   # 100\n",
    "    n=1\n",
    "    # Loop through the rows and columns\n",
    "    for r in range(GRID_ROWS):\n",
    "        for c in range(GRID_COLS):\n",
    "            \n",
    "            # Calculate the pixel coordinates for the slice\n",
    "            y1 = r * cell_height\n",
    "            y2 = y1 + cell_height\n",
    "            x1 = c * cell_width\n",
    "            x2 = x1 + cell_width\n",
    "            \n",
    "            # Use NumPy slicing to extract the cell\n",
    "            # [y1:y2, x1:x2]\n",
    "            cell = image[y1:y2, x1:x2].copy()\n",
    "            if image_mask is None:\n",
    "                mask = np.zeros((y2 - y1, x2 - x1), dtype=bool)\n",
    "            else:\n",
    "                m = np.asarray(image_mask)\n",
    "                if m.ndim == 3:\n",
    "                    m = m[..., 0]\n",
    "                # ensure boolean and correct shape\n",
    "                mask = m[y1:y2, x1:x2].astype(bool)\n",
    "            label = detect_label_in_cell(mask)\n",
    "            final_grid.append(cell)\n",
    "            final_label.append(label)\n",
    "            base = os.path.basename(path)\n",
    "            name_no_ext = os.path.splitext(base)[0]\n",
    "            cell_id = f\"{name_no_ext}_{n}\"\n",
    "            cell_image_path = os.path.join(CELL_OUTPUT_FOLDER, cell_id + \".jpg\")\n",
    "            final_df.loc[len(final_df)] = [cell_id + \".jpg\", name_no_ext,int(label)]\n",
    "            cv2.imwrite(cell_image_path, cell)\n",
    "            n=n+1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c9fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,filename in zip(final_images,final_filenames):\n",
    "    mask = masks[filename]\n",
    "    make_grid(image,mask,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030fa56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"final_labels.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Global Env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
